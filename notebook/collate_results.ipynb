{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "base_path = '/mnt/disk1/heonseok/MPMLD/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_base',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_base_FCNClassifierA',\n"
     ]
    }
   ],
   "source": [
    "dataset = 'location'\n",
    "\n",
    "beta_list = [\n",
    "    # 0.00001,\n",
    "    0.0001,\n",
    "    # 0.001,\n",
    "    # 0.01,\n",
    "    # 0.1,\n",
    "    # 1.0,\n",
    "]\n",
    "\n",
    "z_dim_list = [\n",
    "    # '16',\n",
    "    '64',\n",
    "]\n",
    "\n",
    "setsize_list = [\n",
    "    # '500',\n",
    "    # '1000',\n",
    "    '2000',\n",
    "]\n",
    "\n",
    "lr_list = [\n",
    "    '0.001',\n",
    "    # '0.01',\n",
    "    # '0.1',\n",
    "]\n",
    "\n",
    "ref_list = [\n",
    "    '0.1',\n",
    "]\n",
    "\n",
    "arc_list = [\n",
    "    # 'A',\n",
    "    # 'B',\n",
    "    # 'C',\n",
    "    'D',\n",
    "]\n",
    "\n",
    "dis_type_list = [\n",
    "    'base',\n",
    "    # 'type5',\n",
    "]\n",
    "\n",
    "cw_list = [\n",
    "    '0.01',\n",
    "    '0.1',\n",
    "    '1.0',\n",
    "]\n",
    "\n",
    "mw_list = [\n",
    "    # '0.01',\n",
    "    # '0.1',\n",
    "    '1.0',\n",
    "]\n",
    "\n",
    "recon_model_list = []\n",
    "for beta in beta_list:\n",
    "    for z_dim in z_dim_list:\n",
    "        for setsize in setsize_list:\n",
    "            for lr in lr_list:\n",
    "                for ref in ref_list:\n",
    "                    for arc in arc_list:\n",
    "                        for dis_type in dis_type_list:\n",
    "                            if 'base' in dis_type:\n",
    "                                recon_model = 'VAE{}_z{}_setsize{}_lr{}_ref{}_arc{}_{}'.format(\n",
    "                                    beta, z_dim, setsize, lr, ref, arc, dis_type,\n",
    "                                )\n",
    "                                recon_model_list.append(recon_model)\n",
    "                                continue\n",
    "                            for cw in cw_list:\n",
    "                                for mw in mw_list:\n",
    "                                    recon_model = 'VAE{}_z{}_setsize{}_lr{}_ref{}_arc{}_{}_cw{}_mw{}'.format(\n",
    "                                        beta, z_dim, setsize, lr, ref, arc, dis_type, cw, mw,\n",
    "                                    )\n",
    "                                    recon_model_list.append(recon_model)\n",
    "\n",
    "for recon_model in recon_model_list:\n",
    "    print('\\''+recon_model+'\\',')\n",
    "\n",
    "class_model_list = []\n",
    "for idx in range(len(recon_model_list)):\n",
    "    class_model_list.append(recon_model_list[idx] + '_FCNClassifierA')\n",
    "    print('\\''+class_model_list[idx]+'\\',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw1.0',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw1.0',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw1.0',\n",
      "0.0086,0.0107,0.0106,0.0087,0.0108,0.0107,0.0087,0.0108,0.0107,0.0087,0.0108,0.0107\n",
      "0.0089,0.0110,0.0109,0.0090,0.0110,0.0109,0.0090,0.0110,0.0109,0.0091,0.0111,0.0110\n",
      "0.0076,0.0108,0.0107,0.0077,0.0108,0.0107,0.0077,0.0108,0.0107,0.0077,0.0109,0.0108\n"
     ]
    }
   ],
   "source": [
    "for recon_model in recon_model_list:\n",
    "    print('\\''+recon_model+'\\',')\n",
    "\n",
    "for recon_model in recon_model_list:\n",
    "    recon_path = os.path.join(base_path, dataset, 'reconstructor', recon_model)\n",
    "\n",
    "    # class_acc_full_list = []\n",
    "    # class_acc_content_list = []\n",
    "    # class_acc_style_list = []\n",
    "    # membership_acc_full_list = []\n",
    "    # membership_acc_content_list = []\n",
    "    # membership_acc_style_list = []\n",
    "\n",
    "    for repeat in range(5):\n",
    "        try:\n",
    "            recon_repeat_path = os.path.join(recon_path, 'repeat{}'.format(repeat))\n",
    "            recon_mse_path = os.path.join(recon_repeat_path, 'mse.npy')\n",
    "            recon_mse = np.load(recon_mse_path, allow_pickle=True)\n",
    "            # print(recon_mse)\n",
    "\n",
    "            if repeat == 0:\n",
    "                mse_list = recon_mse\n",
    "            else:\n",
    "                mse_list += recon_mse\n",
    "            # class_acc_full_list.append(recon_acc['class_acc_full'])\n",
    "            # class_acc_content_list.append(recon_acc['class_acc_content'])\n",
    "            # class_acc_style_list.append(recon_acc['class_acc_style'])\n",
    "            # membership_acc_full_list.append(recon_acc['membership_acc_full'])\n",
    "            # membership_acc_content_list.append(recon_acc['membership_acc_content'])\n",
    "            # membership_acc_style_list.append(recon_acc['membership_acc_style'])\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # print('File not found: ', recon_acc_path)\n",
    "            continue\n",
    "\n",
    "    mse_list = mse_list/5\n",
    "\n",
    "    result_list = []\n",
    "    for idx, mse in enumerate(mse_list):\n",
    "        result_list.append('{:.4f}'.format(mse))\n",
    "    print(','.join(result_list))\n",
    "\n",
    "    # result_list = [\n",
    "    #     *recon_model.split('_'),\n",
    "    #     np.average(class_acc_full_list), np.average(class_acc_content_list), np.average(class_acc_style_list),\n",
    "    #     np.average(membership_acc_full_list), np.average(membership_acc_content_list), np.average(membership_acc_style_list)\n",
    "    # ]\n",
    "    #\n",
    "    # for idx, result in enumerate(result_list):\n",
    "    #     if not type(result) is str:\n",
    "    #         result_list[idx] = '{:.4f}'.format(result)\n",
    "    # print(','.join(result_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Reconstruction\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_base',\n",
      "VAE0.0001,z64,setsize2000,lr0.001,ref0.1,arcD,base,0.9515,0.6145,0.5985,0.9960,0.9517,0.9557\n"
     ]
    }
   ],
   "source": [
    "for recon_model in recon_model_list:\n",
    "    print('\\''+recon_model+'\\',')\n",
    "\n",
    "for recon_model in recon_model_list:\n",
    "    recon_path = os.path.join(base_path, dataset, 'reconstructor', recon_model)\n",
    "\n",
    "    class_acc_full_list = []\n",
    "    class_acc_content_list = []\n",
    "    class_acc_style_list = []\n",
    "    membership_acc_full_list = []\n",
    "    membership_acc_content_list = []\n",
    "    membership_acc_style_list = []\n",
    "\n",
    "    for repeat in range(5):\n",
    "        try:\n",
    "            recon_repeat_path = os.path.join(recon_path, 'repeat{}'.format(repeat))\n",
    "            recon_acc_path = os.path.join(recon_repeat_path, 'acc.npy')\n",
    "            recon_acc = np.load(recon_acc_path, allow_pickle=True).item()\n",
    "\n",
    "            class_acc_full_list.append(recon_acc['class_acc_full'])\n",
    "            class_acc_content_list.append(recon_acc['class_acc_content'])\n",
    "            class_acc_style_list.append(recon_acc['class_acc_style'])\n",
    "            membership_acc_full_list.append(recon_acc['membership_acc_full'])\n",
    "            membership_acc_content_list.append(recon_acc['membership_acc_content'])\n",
    "            membership_acc_style_list.append(recon_acc['membership_acc_style'])\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # print('File not found: ', recon_acc_path)\n",
    "            continue\n",
    "\n",
    "    result_list = [\n",
    "        *recon_model.split('_'),\n",
    "        np.average(class_acc_full_list), np.average(class_acc_content_list), np.average(class_acc_style_list),\n",
    "        np.average(membership_acc_full_list), np.average(membership_acc_content_list), np.average(membership_acc_style_list)\n",
    "    ]\n",
    "\n",
    "    for idx, result in enumerate(result_list):\n",
    "        if not type(result) is str:\n",
    "            result_list[idx] = '{:.4f}'.format(result)\n",
    "    print(','.join(result_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Disentanglement\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_base_FCNClassifierA',\n",
      "0.7520,0.6625,0.6100,0.8190,0.6800,0.6375,0.8500,0.6275,0.6375,0.7925,0.6625,0.6375\n"
     ]
    }
   ],
   "source": [
    "for class_model in class_model_list:\n",
    "    print('\\''+class_model+'\\',')\n",
    "\n",
    "for class_model in class_model_list:\n",
    "    class_path = os.path.join(base_path, dataset, 'classifier', class_model)\n",
    "\n",
    "    result_list = []\n",
    "    for recon_type in ['base_z', 'content_z', 'style_z', 'full_z']:\n",
    "        train_acc_list = []\n",
    "        valid_acc_list = []\n",
    "        test_acc_list = []\n",
    "        for repeat in range(5):\n",
    "            try:\n",
    "                class_repeat_path = os.path.join(class_path, recon_type, 'repeat{}'.format(repeat))\n",
    "                class_acc = np.load(os.path.join(class_repeat_path, 'acc.npy'), allow_pickle=True).item()\n",
    "                train_acc_list.append(class_acc['train'])\n",
    "                valid_acc_list.append(class_acc['valid'])\n",
    "                test_acc_list.append(class_acc['test'])\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                # print('File not found: ', class_repeat_path)\n",
    "                continue\n",
    "\n",
    "        result_list.extend([np.average(train_acc_list), np.average(valid_acc_list), np.average(test_acc_list)])\n",
    "\n",
    "    for idx, result in enumerate(result_list):\n",
    "        if not type(result) is str:\n",
    "            result_list[idx] = '{:.4f}'.format(result)\n",
    "    print(','.join(result_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Classification\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_base_FCNClassifierA',\n",
      "0.5360,0.5533,0.5515,0.6050,0.5415,0.5717,0.5455,0.5683\n"
     ]
    }
   ],
   "source": [
    "metric = 'acc'\n",
    "# metric = 'auroc'\n",
    "\n",
    "attack_type_list = ['stat', 'black']\n",
    "for class_model in class_model_list:\n",
    "    print('\\''+class_model+'\\',')\n",
    "\n",
    "for class_model in class_model_list:\n",
    "    attack_path = os.path.join(base_path, dataset, 'attacker', class_model)\n",
    "\n",
    "    result_list = []\n",
    "    for recon_type in ['base_z', 'content_z', 'style_z', 'full_z']:\n",
    "        stat_acc_list = []\n",
    "        black_acc_list = []\n",
    "        # white_acc_list = []\n",
    "        for repeat in range(5):\n",
    "            for attack_type in attack_type_list:\n",
    "                attack_repeat_path = os.path.join(attack_path, recon_type, 'repeat{}'.format(repeat))\n",
    "                try:\n",
    "                    attack_acc = np.load(os.path.join(attack_repeat_path, attack_type, '{}.npy'.format(metric)), allow_pickle=True)\n",
    "                    if attack_type == 'stat':\n",
    "                        stat_acc_list.append(attack_acc)\n",
    "                    elif attack_type == 'black':\n",
    "                        black_acc_list.append(attack_acc.item()['test'])\n",
    "                    # elif attack_type == 'white':\n",
    "                    #     white_acc_list.append(attack_acc.item()['test'])\n",
    "\n",
    "                except FileNotFoundError:\n",
    "                    # print('File not found: ', attack_repeat_path)\n",
    "                    continue\n",
    "\n",
    "        result_list.extend([np.average(stat_acc_list), np.average(black_acc_list)])\n",
    "\n",
    "    for idx, result in enumerate(result_list):\n",
    "        if not type(result) is str:\n",
    "            result_list[idx] = '{:.4f}'.format(result)\n",
    "    print(','.join(result_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Attack\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9420 0.6850 0.6535 0.6066 0.7298\n"
     ]
    }
   ],
   "source": [
    "# metric = 'acc'\n",
    "metric = 'auroc'\n",
    "\n",
    "classifier_with_raw_data = 'original_setsize2000_FCNClassifierA'\n",
    "class_path = os.path.join(base_path, dataset, 'classifier', classifier_with_raw_data)\n",
    "attack_path = os.path.join(base_path, dataset, 'attacker', classifier_with_raw_data)\n",
    "train_acc_list = []\n",
    "valid_acc_list = []\n",
    "test_acc_list = []\n",
    "stat_acc_list = []\n",
    "black_acc_list = []\n",
    "for repeat in range(5):\n",
    "    try:\n",
    "        class_repeat_path = os.path.join(class_path, 'repeat{}'.format(repeat))\n",
    "        attack_repeat_path = os.path.join(attack_path, 'repeat{}'.format(repeat))\n",
    "\n",
    "        class_acc = np.load(os.path.join(class_repeat_path, 'acc.npy'), allow_pickle=True).item()\n",
    "        train_acc_list.append(class_acc['train'])\n",
    "        valid_acc_list.append(class_acc['valid'])\n",
    "        test_acc_list.append(class_acc['test'])\n",
    "\n",
    "        for attack_type in attack_type_list:\n",
    "            attack_acc = np.load(os.path.join(attack_repeat_path, attack_type, '{}.npy'.format(metric)), allow_pickle=True)\n",
    "            if attack_type == 'stat':\n",
    "                stat_acc_list.append(attack_acc)\n",
    "            elif attack_type == 'black':\n",
    "                black_acc_list.append(attack_acc.item()['test'])\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # print('File not found: ', class_repeat_path)\n",
    "        continue\n",
    "\n",
    "print('{:.4f} {:.4f} {:.4f} {:.4f} {:.4f}'.format(\n",
    "    np.average(train_acc_list), np.average(valid_acc_list), np.average(test_acc_list),\n",
    "    np.average(stat_acc_list), np.average(black_acc_list),\n",
    "))\n",
    "# print(np.average(train_acc_list), np.average(valid_acc_list), np.average(test_acc_list))\n",
    "# print(np.average(stat_acc_list), np.average(black_acc_list), np.average(test_acc_list))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% original_setsize2000\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}