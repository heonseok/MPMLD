{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "base_path = '/mnt/disk1/heonseok/MPMLD/output0727'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def get_model_list(beta_list, z_dim_list, setsize_list, lr_list, ref_list, weight_list):\n",
    "    recon_model_list = []\n",
    "    recon_spec_list = []\n",
    "    for beta in beta_list:\n",
    "        for z_dim in z_dim_list:\n",
    "            for setsize in setsize_list:\n",
    "                for lr in lr_list:\n",
    "                    for ref in ref_list:\n",
    "                        for weight in weight_list:\n",
    "                            recon_model = 'VAE{}_z{}_setsize{}_lr{}_ref{}_rw{}_cc{}_cm{}_mc{}_mm{}'.format(\n",
    "                                beta, z_dim, setsize, lr, ref, float(weight[0]), float(weight[1]), float(weight[2]), float(weight[3]), float(weight[4]), )\n",
    "                            recon_model_list.append(recon_model)\n",
    "                            recon_spec_list.append([beta, z_dim, setsize, lr, ref, weight[0], weight[1], weight[2], weight[3], weight[4]])\n",
    "\n",
    "    for recon_model in recon_model_list:\n",
    "        print('\\''+recon_model+'\\',')\n",
    "\n",
    "    class_model_list = []\n",
    "    for idx in range(len(recon_model_list)):\n",
    "        class_model_list.append(recon_model_list[idx] + '_ResNet18')\n",
    "        # print('\\''+class_model_list[idx]+'\\',')\n",
    "\n",
    "    for recon_spec in recon_spec_list:\n",
    "        # print(*recon_spec)\n",
    "        spec_str = ''\n",
    "        for spec in recon_spec:\n",
    "            spec_str += str(spec) + ','\n",
    "        print(spec_str)\n",
    "    return recon_model_list, class_model_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def collate_reconstruction_results(dataset, recon_model_list):\n",
    "    for recon_model in recon_model_list:\n",
    "        print('\\''+recon_model+'\\',')\n",
    "\n",
    "    for recon_model in recon_model_list:\n",
    "        recon_path = os.path.join(base_path, dataset, 'reconstructor', recon_model)\n",
    "\n",
    "        for repeat in range(5):\n",
    "            try:\n",
    "                recon_repeat_path = os.path.join(recon_path, 'repeat{}'.format(repeat))\n",
    "                recon_mse_path = os.path.join(recon_repeat_path, 'mse.npy')\n",
    "                recon_mse = np.load(recon_mse_path, allow_pickle=True)\n",
    "\n",
    "                if repeat == 0:\n",
    "                    mse_list = recon_mse\n",
    "                else:\n",
    "                    mse_list += recon_mse\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                # print('File not found: ', recon_acc_path)\n",
    "                continue\n",
    "\n",
    "        mse_list = mse_list/5\n",
    "\n",
    "        result_list = []\n",
    "        for idx, mse in enumerate(mse_list):\n",
    "            result_list.append('{:.4f}'.format(mse))\n",
    "        print(','.join(result_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Reconstruction\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def collate_disentanglement_result(dataset, recon_model_list):\n",
    "    for recon_model in recon_model_list:\n",
    "        print('\\''+recon_model+'\\',')\n",
    "\n",
    "    for recon_model in recon_model_list:\n",
    "        recon_path = os.path.join(base_path, dataset, 'reconstructor', recon_model)\n",
    "\n",
    "        class_fz_list = []\n",
    "        class_cz_list = []\n",
    "        class_mz_list = []\n",
    "        membership_fz_list = []\n",
    "        membership_cz_list = []\n",
    "        membership_mz_list = []\n",
    "\n",
    "        for repeat in range(5):\n",
    "            try:\n",
    "                recon_repeat_path = os.path.join(recon_path, 'repeat{}'.format(repeat))\n",
    "                recon_acc_path = os.path.join(recon_repeat_path, 'acc.npy')\n",
    "                recon_acc = np.load(recon_acc_path, allow_pickle=True).item()\n",
    "\n",
    "                class_fz_list.append(recon_acc['class_acc_full'])\n",
    "                class_cz_list.append(recon_acc['class_acc_content'])\n",
    "                class_mz_list.append(recon_acc['class_acc_style'])\n",
    "\n",
    "                membership_fz_list.append(recon_acc['membership_acc_full'])\n",
    "                membership_cz_list.append(recon_acc['membership_acc_content'])\n",
    "                membership_mz_list.append(recon_acc['membership_acc_style'])\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                # print('File not found: ', recon_acc_path)\n",
    "                continue\n",
    "\n",
    "        result_list = [\n",
    "            # *recon_model.split('_'),\n",
    "            np.average(class_fz_list), np.average(class_cz_list), np.average(class_mz_list),\n",
    "            np.average(membership_fz_list), np.average(membership_cz_list), np.average(membership_mz_list)\n",
    "        ]\n",
    "\n",
    "        for idx, result in enumerate(result_list):\n",
    "            if not type(result) is str:\n",
    "                result_list[idx] = '{:.4f}'.format(result)\n",
    "        print(','.join(result_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Disentanglement\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def collate_classification_result(dataset, class_model_list):\n",
    "    for class_model in class_model_list:\n",
    "        print('\\''+class_model+'\\',')\n",
    "\n",
    "    for class_model in class_model_list:\n",
    "        class_path = os.path.join(base_path, dataset, 'classifier', class_model)\n",
    "\n",
    "        result_list = []\n",
    "        for recon_type in recon_list:\n",
    "            train_acc_list = []\n",
    "            valid_acc_list = []\n",
    "            test_acc_list = []\n",
    "            for repeat in range(5):\n",
    "                try:\n",
    "                    class_repeat_path = os.path.join(class_path, recon_type, 'repeat{}'.format(repeat))\n",
    "                    class_acc = np.load(os.path.join(class_repeat_path, 'acc.npy'), allow_pickle=True).item()\n",
    "                    train_acc_list.append(class_acc['train'])\n",
    "                    valid_acc_list.append(class_acc['valid'])\n",
    "                    test_acc_list.append(class_acc['test'])\n",
    "\n",
    "                except FileNotFoundError:\n",
    "                    # print('File not found: ', class_repeat_path)\n",
    "                    continue\n",
    "\n",
    "            result_list.extend([\n",
    "                np.average(train_acc_list),\n",
    "                np.average(valid_acc_list),\n",
    "                np.average(test_acc_list)\n",
    "            ])\n",
    "\n",
    "        for idx, result in enumerate(result_list):\n",
    "            if not type(result) is str:\n",
    "                result_list[idx] = '{:.4f}'.format(result)\n",
    "        print(','.join(result_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Classification\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def collate_attack_result(dataset, class_model_list):\n",
    "    metric = 'acc'\n",
    "    # metric = 'auroc'\n",
    "\n",
    "    attack_type_list = [\n",
    "        'stat',\n",
    "        'black',\n",
    "        # 'white',\n",
    "    ]\n",
    "    for class_model in class_model_list:\n",
    "        print('\\''+class_model+'\\',')\n",
    "\n",
    "    for class_model in class_model_list:\n",
    "        attack_path = os.path.join(base_path, dataset, 'attacker', class_model)\n",
    "        result_list = []\n",
    "        for recon_type in recon_list:\n",
    "            # white_acc_list = []\n",
    "            for attack_type in attack_type_list:\n",
    "                for repeat in range(5):\n",
    "\n",
    "                    acc_list = []\n",
    "                    attack_repeat_path = os.path.join(attack_path, recon_type, 'repeat{}'.format(repeat))\n",
    "                    try:\n",
    "                        attack_acc = np.load(os.path.join(attack_repeat_path, attack_type, '{}.npy'.format(metric)), allow_pickle=True)\n",
    "                        if attack_type == 'stat':\n",
    "                            acc_list.append(attack_acc)\n",
    "                        elif attack_type == 'black':\n",
    "                            acc_list.append(attack_acc.item()['test'])\n",
    "                        # elif attack_type == 'white':\n",
    "                        #     white_acc_list.append(attack_acc.item()['test'])\n",
    "\n",
    "                    except FileNotFoundError:\n",
    "                        # print('File not found: ', attack_repeat_path)\n",
    "                        continue\n",
    "\n",
    "                    result_list.extend([np.average(acc_list)])\n",
    "\n",
    "        for idx, result in enumerate(result_list):\n",
    "            if not type(result) is str:\n",
    "                result_list[idx] = '{:.4f}'.format(result)\n",
    "        print(','.join(result_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Attack\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9486 0.6470 0.5900 0.6420 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heonseok/anaconda3/envs/pysyft/lib/python3.7/site-packages/numpy/lib/function_base.py:390: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/heonseok/anaconda3/envs/pysyft/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Todo : refactoring\n",
    "metric = 'acc'\n",
    "# metric = 'auroc'\n",
    "\n",
    "classifier_with_raw_data = 'original_setsize1000_FCNClassifierA'\n",
    "class_path = os.path.join(base_path, dataset, 'classifier', classifier_with_raw_data)\n",
    "attack_path = os.path.join(base_path, dataset, 'attacker', classifier_with_raw_data)\n",
    "train_acc_list = []\n",
    "valid_acc_list = []\n",
    "test_acc_list = []\n",
    "stat_acc_list = []\n",
    "black_acc_list = []\n",
    "for repeat in range(5):\n",
    "    try:\n",
    "        class_repeat_path = os.path.join(class_path, 'repeat{}'.format(repeat))\n",
    "        attack_repeat_path = os.path.join(attack_path, 'repeat{}'.format(repeat))\n",
    "\n",
    "        class_acc = np.load(os.path.join(class_repeat_path, 'acc.npy'), allow_pickle=True).item()\n",
    "        train_acc_list.append(class_acc['train'])\n",
    "        valid_acc_list.append(class_acc['valid'])\n",
    "        test_acc_list.append(class_acc['test'])\n",
    "\n",
    "        for attack_type in attack_type_list:\n",
    "            attack_acc = np.load(os.path.join(attack_repeat_path, attack_type, '{}.npy'.format(metric)), allow_pickle=True)\n",
    "            if attack_type == 'stat':\n",
    "                stat_acc_list.append(attack_acc)\n",
    "            elif attack_type == 'black':\n",
    "                black_acc_list.append(attack_acc.item()['test'])\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # print('File not found: ', class_repeat_path)\n",
    "        continue\n",
    "\n",
    "print('{:.4f} {:.4f} {:.4f} {:.4f} {:.4f}'.format(\n",
    "    np.average(train_acc_list), np.average(valid_acc_list), np.average(test_acc_list),\n",
    "    np.average(stat_acc_list), np.average(black_acc_list),\n",
    "))\n",
    "# print(np.average(train_acc_list), np.average(valid_acc_list), np.average(test_acc_list))\n",
    "# print(np.average(stat_acc_list), np.average(black_acc_list), np.average(test_acc_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% original_setsize2000\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw1.0_cc0.0_cm1.0_mc1.0_mm0.0',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw1.0_cc0.0_cm10.0_mc1.0_mm0.0',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw1.0_cc0.0_cm1.0_mc10.0_mm0.0',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw1.0_cc0.0_cm10.0_mc10.0_mm0.0',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw1.0_cc1.0_cm1.0_mc1.0_mm1.0',\n",
      "1e-06,64,10000,0.001,1.0,1,0,1,1,0,\n",
      "1e-06,64,10000,0.001,1.0,1,0,10,1,0,\n",
      "1e-06,64,10000,0.001,1.0,1,0,1,10,0,\n",
      "1e-06,64,10000,0.001,1.0,1,0,10,10,0,\n",
      "1e-06,64,10000,0.001,1.0,1,1,1,1,1,\n"
     ]
    }
   ],
   "source": [
    "dataset = 'SVHN'\n",
    "\n",
    "beta_list = [\n",
    "    0.000001,\n",
    "    # 0.00001,\n",
    "    # 0.0001,\n",
    "    # 0.001,\n",
    "    # 0.01,\n",
    "    # 0.1,\n",
    "    # 1.0,\n",
    "]\n",
    "\n",
    "z_dim_list = [\n",
    "    # '16',\n",
    "    '64',\n",
    "    # '128'\n",
    "    # '256',\n",
    "]\n",
    "\n",
    "setsize_list = [\n",
    "    # '500',\n",
    "    # '1000',\n",
    "    # '2000',\n",
    "    '10000',\n",
    "]\n",
    "\n",
    "lr_list = [\n",
    "    '0.001',\n",
    "    # '0.01',\n",
    "    # '0.1',\n",
    "]\n",
    "\n",
    "ref_list = [\n",
    "    # '0.1',\n",
    "    '1.0',\n",
    "]\n",
    "\n",
    "\n",
    "weight_list = [\n",
    "    # ref 1.0 + permuted ref\n",
    "    # [100., 0., 1., 1., 0.], # best result at 0727 6:37\n",
    "    # [100., 0., 10., 1., 0.],\n",
    "    # [100., 0., 1., 10., 0.],\n",
    "    # [100., 0., 10., 10., 0.],\n",
    "    # [100., 1., 1., 1., 1.],\n",
    "\n",
    "    [1, 0, 1, 1, 0],\n",
    "    [1, 0, 10, 1, 0],\n",
    "    [1, 0, 1, 10, 0],\n",
    "    [1, 0, 10, 10, 0],\n",
    "    [1, 1, 1, 1, 1],\n",
    "]\n",
    "\n",
    "recon_model_list, class_model_list = get_model_list(beta_list, z_dim_list, setsize_list, lr_list, ref_list, weight_list)\n",
    "\n",
    "recon_list = [\n",
    "    'cb_mb',\n",
    "    'cz_mb',\n",
    "    'cb_mz',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw1.0_cc0.0_cm1.0_mc1.0_mm0.0',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw1.0_cc0.0_cm10.0_mc1.0_mm0.0',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw1.0_cc0.0_cm1.0_mc10.0_mm0.0',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw1.0_cc0.0_cm10.0_mc10.0_mm0.0',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw1.0_cc1.0_cm1.0_mc1.0_mm1.0',\n",
      "0.5148,0.4786,0.1926,0.5000,0.5000,0.5000\n",
      "0.6501,0.6350,0.1926,0.5000,0.5000,0.5009\n",
      "0.7095,0.6356,0.1926,0.5000,0.5000,0.5112\n",
      "0.2252,0.2107,0.1923,0.5000,0.5000,0.5000\n",
      "0.1942,0.1940,0.1924,0.5000,0.5000,0.5000\n"
     ]
    }
   ],
   "source": [
    "collate_disentanglement_result(dataset, recon_model_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw100.0_cc0.0_cm1.0_mc1.0_mm0.0_ResNet18',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw100.0_cc0.0_cm10.0_mc1.0_mm0.0_ResNet18',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw100.0_cc0.0_cm1.0_mc10.0_mm0.0_ResNet18',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw100.0_cc0.0_cm10.0_mc10.0_mm0.0_ResNet18',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw100.0_cc1.0_cm1.0_mc1.0_mm1.0_ResNet18',\n",
      "1.0000,0.8820,0.8665,0.3204,0.1960,0.1885,0.6960,0.5100,0.4835\n",
      "1.0000,0.8600,0.8485,0.9773,0.1830,0.1685,1.0000,0.6195,0.6230\n",
      "1.0000,0.8820,0.8690,0.2248,0.1730,0.1725,0.9944,0.3820,0.3730\n",
      "1.0000,0.8570,0.8435,0.1791,0.1560,0.1575,0.5810,0.2695,0.2695\n",
      "1.0000,0.8345,0.8110,0.3609,0.1520,0.1595,1.0000,0.5250,0.5210\n"
     ]
    }
   ],
   "source": [
    "collate_classification_result(dataset, class_model_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw100.0_cc0.0_cm1.0_mc1.0_mm0.0_ResNet18',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw100.0_cc0.0_cm10.0_mc1.0_mm0.0_ResNet18',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw100.0_cc0.0_cm1.0_mc10.0_mm0.0_ResNet18',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw100.0_cc0.0_cm10.0_mc10.0_mm0.0_ResNet18',\n",
      "'VAE1e-06_z64_setsize10000_lr0.001_ref1.0_rw100.0_cc1.0_cm1.0_mc1.0_mm1.0_ResNet18',\n",
      "0.6942,0.6567,0.5312,0.6763,0.5372,0.5653\n",
      "0.6886,0.6767,0.8206,0.9187,0.7965,0.7713\n",
      "0.7152,0.6793,0.5133,0.6123,0.7507,0.7837\n",
      "0.7020,0.6880,0.5053,0.5310,0.5394,0.5673\n",
      "0.7180,0.6997,0.5247,0.6063,0.7500,0.7550\n"
     ]
    }
   ],
   "source": [
    "collate_attack_result(dataset, class_model_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}