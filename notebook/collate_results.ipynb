{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "base_path = '/mnt/disk1/heonseok/MPMLD/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw0.01',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw0.1',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw1.0',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw0.01',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw0.1',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw1.0',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw0.01',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw0.1',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw1.0',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw0.01',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw0.1',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw1.0',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw0.01',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw0.1',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw1.0',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw0.01',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw0.1',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw1.0',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw0.01_FCNClassifierA',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw0.1_FCNClassifierA',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw1.0_FCNClassifierA',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw0.01_FCNClassifierA',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw0.1_FCNClassifierA',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw1.0_FCNClassifierA',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw0.01_FCNClassifierA',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw0.1_FCNClassifierA',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw1.0_FCNClassifierA',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw0.01_FCNClassifierA',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw0.1_FCNClassifierA',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw1.0_FCNClassifierA',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw0.01_FCNClassifierA',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw0.1_FCNClassifierA',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw1.0_FCNClassifierA',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw0.01_FCNClassifierA',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw0.1_FCNClassifierA',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw1.0_FCNClassifierA',\n"
     ]
    }
   ],
   "source": [
    "dataset = 'location'\n",
    "\n",
    "beta_list = [\n",
    "    0.0001,\n",
    "    0.001,\n",
    "    # 0.01,\n",
    "    # 0.1,\n",
    "    # 1.0,\n",
    "]\n",
    "\n",
    "z_dim_list = [\n",
    "    # '16',\n",
    "    '64',\n",
    "]\n",
    "\n",
    "setsize_list = [\n",
    "    # '500',\n",
    "    # '1000',\n",
    "    '2000',\n",
    "]\n",
    "\n",
    "lr_list = [\n",
    "    '0.001',\n",
    "    # '0.01',\n",
    "    # '0.1',\n",
    "]\n",
    "\n",
    "ref_list = [\n",
    "    '0.1',\n",
    "]\n",
    "\n",
    "arc_list = [\n",
    "    # 'A',\n",
    "    # 'B',\n",
    "    # 'C',\n",
    "    'D',\n",
    "]\n",
    "\n",
    "dis_type_list = [\n",
    "    # 'base',\n",
    "    'type5',\n",
    "]\n",
    "\n",
    "cw_list = [\n",
    "    '0.01',\n",
    "    '0.1',\n",
    "    '1.0',\n",
    "]\n",
    "\n",
    "mw_list = [\n",
    "    '0.01',\n",
    "    '0.1',\n",
    "    '1.0',\n",
    "]\n",
    "\n",
    "recon_model_list = []\n",
    "for beta in beta_list:\n",
    "    for z_dim in z_dim_list:\n",
    "        for setsize in setsize_list:\n",
    "            for lr in lr_list:\n",
    "                for ref in ref_list:\n",
    "                    for arc in arc_list:\n",
    "                        for dis_type in dis_type_list:\n",
    "                            if 'base' in dis_type:\n",
    "                                recon_model = 'VAE{}_z{}_setsize{}_lr{}_ref{}_arc{}_{}'.format(\n",
    "                                    beta, z_dim, setsize, lr, ref, arc, dis_type,\n",
    "                                )\n",
    "                                recon_model_list.append(recon_model)\n",
    "                                continue\n",
    "                            for cw in cw_list:\n",
    "                                for mw in mw_list:\n",
    "                                    recon_model = 'VAE{}_z{}_setsize{}_lr{}_ref{}_arc{}_{}_cw{}_mw{}'.format(\n",
    "                                        beta, z_dim, setsize, lr, ref, arc, dis_type, cw, mw,\n",
    "                                    )\n",
    "                                    recon_model_list.append(recon_model)\n",
    "\n",
    "for recon_model in recon_model_list:\n",
    "    print('\\''+recon_model+'\\',')\n",
    "\n",
    "class_model_list = []\n",
    "for idx in range(len(recon_model_list)):\n",
    "    class_model_list.append(recon_model_list[idx] + '_FCNClassifierA')\n",
    "    print('\\''+class_model_list[idx]+'\\',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VAE0.1_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw0.01_mw0.01',\n",
      "'VAE0.1_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw0.01_mw0.1',\n",
      "'VAE0.1_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw0.01_mw1.0',\n",
      "'VAE0.1_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw0.1_mw0.01',\n",
      "'VAE0.1_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw0.1_mw0.1',\n",
      "'VAE0.1_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw0.1_mw1.0',\n",
      "'VAE0.1_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw1.0_mw0.01',\n",
      "'VAE0.1_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw1.0_mw0.1',\n",
      "'VAE0.1_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw1.0_mw1.0',\n",
      "'VAE1.0_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw0.01_mw0.01',\n",
      "'VAE1.0_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw0.01_mw0.1',\n",
      "'VAE1.0_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw0.01_mw1.0',\n",
      "'VAE1.0_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw0.1_mw0.01',\n",
      "'VAE1.0_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw0.1_mw0.1',\n",
      "'VAE1.0_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw0.1_mw1.0',\n",
      "'VAE1.0_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw1.0_mw0.01',\n",
      "'VAE1.0_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw1.0_mw0.1',\n",
      "'VAE1.0_z64_setsize2000_lr0.001_ref0.1_arcC_type5_cw1.0_mw1.0',\n",
      "0.0026,0.0028,0.0028,0.0028,0.0029,0.0029,0.0037,0.0038,0.0038\n",
      "0.0005,0.0006,0.0006,0.0006,0.0006,0.0006,0.0007,0.0008,0.0008\n",
      "0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0002,0.0002\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n"
     ]
    }
   ],
   "source": [
    "for recon_model in recon_model_list:\n",
    "    print('\\''+recon_model+'\\',')\n",
    "\n",
    "for recon_model in recon_model_list:\n",
    "    recon_path = os.path.join(base_path, dataset, 'reconstructor', recon_model)\n",
    "\n",
    "    # class_acc_full_list = []\n",
    "    # class_acc_content_list = []\n",
    "    # class_acc_style_list = []\n",
    "    # membership_acc_full_list = []\n",
    "    # membership_acc_content_list = []\n",
    "    # membership_acc_style_list = []\n",
    "\n",
    "    for repeat in range(5):\n",
    "        try:\n",
    "            recon_repeat_path = os.path.join(recon_path, 'repeat{}'.format(repeat))\n",
    "            recon_mse_path = os.path.join(recon_repeat_path, 'mse.npy')\n",
    "            recon_mse = np.load(recon_mse_path, allow_pickle=True)\n",
    "            # print(recon_mse)\n",
    "\n",
    "            if repeat == 0:\n",
    "                mse_list = recon_mse\n",
    "            else:\n",
    "                mse_list += recon_mse\n",
    "            # class_acc_full_list.append(recon_acc['class_acc_full'])\n",
    "            # class_acc_content_list.append(recon_acc['class_acc_content'])\n",
    "            # class_acc_style_list.append(recon_acc['class_acc_style'])\n",
    "            # membership_acc_full_list.append(recon_acc['membership_acc_full'])\n",
    "            # membership_acc_content_list.append(recon_acc['membership_acc_content'])\n",
    "            # membership_acc_style_list.append(recon_acc['membership_acc_style'])\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # print('File not found: ', recon_acc_path)\n",
    "            continue\n",
    "\n",
    "    mse_list = mse_list/5\n",
    "\n",
    "    result_list = []\n",
    "    for idx, mse in enumerate(mse_list):\n",
    "        result_list.append('{:.4f}'.format(mse))\n",
    "    print(','.join(result_list))\n",
    "\n",
    "    # result_list = [\n",
    "    #     *recon_model.split('_'),\n",
    "    #     np.average(class_acc_full_list), np.average(class_acc_content_list), np.average(class_acc_style_list),\n",
    "    #     np.average(membership_acc_full_list), np.average(membership_acc_content_list), np.average(membership_acc_style_list)\n",
    "    # ]\n",
    "    #\n",
    "    # for idx, result in enumerate(result_list):\n",
    "    #     if not type(result) is str:\n",
    "    #         result_list[idx] = '{:.4f}'.format(result)\n",
    "    # print(','.join(result_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Reconstruction\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw0.01',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw0.1',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw1.0',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw0.01',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw0.1',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw1.0',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw0.01',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw0.1',\n",
      "'VAE0.0001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw1.0',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw0.01',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw0.1',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.01_mw1.0',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw0.01',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw0.1',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw0.1_mw1.0',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw0.01',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw0.1',\n",
      "'VAE0.001_z64_setsize2000_lr0.001_ref0.1_arcD_type5_cw1.0_mw1.0',\n",
      "VAE0.0001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw0.01,mw0.01,0.1045,0.1105,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.0001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw0.01,mw0.1,0.1590,0.1665,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.0001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw0.01,mw1.0,0.1315,0.1235,0.0620,0.5000,0.5000,0.5000\n",
      "VAE0.0001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw0.1,mw0.01,0.1600,0.1555,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.0001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw0.1,mw0.1,0.1470,0.1305,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.0001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw0.1,mw1.0,0.1315,0.1235,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.0001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw1.0,mw0.01,0.1310,0.1170,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.0001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw1.0,mw0.1,0.1315,0.1215,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.0001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw1.0,mw1.0,0.1430,0.1360,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw0.01,mw0.01,0.0655,0.0655,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw0.01,mw0.1,0.0655,0.0655,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw0.01,mw1.0,0.0650,0.0655,0.0660,0.5000,0.5000,0.5000\n",
      "VAE0.001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw0.1,mw0.01,0.0655,0.0655,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw0.1,mw0.1,0.0655,0.0655,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw0.1,mw1.0,0.0655,0.0655,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw1.0,mw0.01,0.0655,0.0655,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw1.0,mw0.1,0.0655,0.0655,0.0655,0.5000,0.5000,0.5000\n",
      "VAE0.001,z64,setsize2000,lr0.001,ref0.1,arcD,type5,cw1.0,mw1.0,0.0645,0.0655,0.0655,0.5000,0.5000,0.5000\n"
     ]
    }
   ],
   "source": [
    "for recon_model in recon_model_list:\n",
    "    print('\\''+recon_model+'\\',')\n",
    "\n",
    "for recon_model in recon_model_list:\n",
    "    recon_path = os.path.join(base_path, dataset, 'reconstructor', recon_model)\n",
    "\n",
    "    class_acc_full_list = []\n",
    "    class_acc_content_list = []\n",
    "    class_acc_style_list = []\n",
    "    membership_acc_full_list = []\n",
    "    membership_acc_content_list = []\n",
    "    membership_acc_style_list = []\n",
    "\n",
    "    for repeat in range(5):\n",
    "        try:\n",
    "            recon_repeat_path = os.path.join(recon_path, 'repeat{}'.format(repeat))\n",
    "            recon_acc_path = os.path.join(recon_repeat_path, 'acc.npy')\n",
    "            recon_acc = np.load(recon_acc_path, allow_pickle=True).item()\n",
    "\n",
    "            class_acc_full_list.append(recon_acc['class_acc_full'])\n",
    "            class_acc_content_list.append(recon_acc['class_acc_content'])\n",
    "            class_acc_style_list.append(recon_acc['class_acc_style'])\n",
    "            membership_acc_full_list.append(recon_acc['membership_acc_full'])\n",
    "            membership_acc_content_list.append(recon_acc['membership_acc_content'])\n",
    "            membership_acc_style_list.append(recon_acc['membership_acc_style'])\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # print('File not found: ', recon_acc_path)\n",
    "            continue\n",
    "\n",
    "    result_list = [\n",
    "        *recon_model.split('_'),\n",
    "        np.average(class_acc_full_list), np.average(class_acc_content_list), np.average(class_acc_style_list),\n",
    "        np.average(membership_acc_full_list), np.average(membership_acc_content_list), np.average(membership_acc_style_list)\n",
    "    ]\n",
    "\n",
    "    for idx, result in enumerate(result_list):\n",
    "        if not type(result) is str:\n",
    "            result_list[idx] = '{:.4f}'.format(result)\n",
    "    print(','.join(result_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Disentanglement\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for class_model in class_model_list:\n",
    "    print('\\''+class_model+'\\',')\n",
    "\n",
    "for class_model in class_model_list:\n",
    "    class_path = os.path.join(base_path, dataset, 'classifier', class_model)\n",
    "\n",
    "    result_list = []\n",
    "    for recon_type in ['full_z', 'content_z', 'style_z']:\n",
    "        train_acc_list = []\n",
    "        valid_acc_list = []\n",
    "        test_acc_list = []\n",
    "        for repeat in range(5):\n",
    "            try:\n",
    "                class_repeat_path = os.path.join(class_path, recon_type, 'repeat{}'.format(repeat))\n",
    "                class_acc = np.load(os.path.join(class_repeat_path, 'acc.npy'), allow_pickle=True).item()\n",
    "                train_acc_list.append(class_acc['train'])\n",
    "                valid_acc_list.append(class_acc['valid'])\n",
    "                test_acc_list.append(class_acc['test'])\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                # print('File not found: ', class_repeat_path)\n",
    "                continue\n",
    "\n",
    "        result_list.extend([np.average(train_acc_list), np.average(valid_acc_list), np.average(test_acc_list)])\n",
    "\n",
    "    for idx, result in enumerate(result_list):\n",
    "        if not type(result) is str:\n",
    "            result_list[idx] = '{:.4f}'.format(result)\n",
    "    print(','.join(result_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Classification\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attack_type_list = ['stat', 'black']\n",
    "for class_model in class_model_list:\n",
    "    print('\\''+class_model+'\\',')\n",
    "\n",
    "for class_model in class_model_list:\n",
    "    attack_path = os.path.join(base_path, dataset, 'attacker', class_model)\n",
    "\n",
    "    result_list = []\n",
    "    for recon_type in ['full_z', 'content_z', 'style_z']:\n",
    "        stat_acc_list = []\n",
    "        black_acc_list = []\n",
    "        # white_acc_list = []\n",
    "        for repeat in range(5):\n",
    "            for attack_type in attack_type_list:\n",
    "                attack_repeat_path = os.path.join(attack_path, recon_type, 'repeat{}'.format(repeat))\n",
    "                try:\n",
    "                    attack_acc = np.load(os.path.join(attack_repeat_path, attack_type, 'acc.npy'), allow_pickle=True)\n",
    "                    if attack_type == 'stat':\n",
    "                        stat_acc_list.append(attack_acc)\n",
    "                    elif attack_type == 'black':\n",
    "                        black_acc_list.append(attack_acc.item()['test'])\n",
    "                    # elif attack_type == 'white':\n",
    "                    #     white_acc_list.append(attack_acc.item()['test'])\n",
    "\n",
    "                except FileNotFoundError:\n",
    "                    print('File not found: ', attack_repeat_path)\n",
    "                    continue\n",
    "\n",
    "        result_list.extend([np.average(stat_acc_list), np.average(black_acc_list)])\n",
    "\n",
    "    for idx, result in enumerate(result_list):\n",
    "        if not type(result) is str:\n",
    "            result_list[idx] = '{:.4f}'.format(result)\n",
    "    print(','.join(result_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Attack\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier_with_raw_data = 'original_setsize2000_FCNClassifierA'\n",
    "class_path = os.path.join(base_path, dataset, 'classifier', classifier_with_raw_data)\n",
    "attack_path = os.path.join(base_path, dataset, 'attacker', classifier_with_raw_data)\n",
    "train_acc_list = []\n",
    "valid_acc_list = []\n",
    "test_acc_list = []\n",
    "stat_acc_list = []\n",
    "black_acc_list = []\n",
    "for repeat in range(5):\n",
    "    try:\n",
    "        class_repeat_path = os.path.join(class_path, 'repeat{}'.format(repeat))\n",
    "        attack_repeat_path = os.path.join(attack_path, 'repeat{}'.format(repeat))\n",
    "\n",
    "        class_acc = np.load(os.path.join(class_repeat_path, 'acc.npy'), allow_pickle=True).item()\n",
    "        train_acc_list.append(class_acc['train'])\n",
    "        valid_acc_list.append(class_acc['valid'])\n",
    "        test_acc_list.append(class_acc['test'])\n",
    "\n",
    "        for attack_type in attack_type_list:\n",
    "            attack_acc = np.load(os.path.join(attack_repeat_path, attack_type, 'acc.npy'), allow_pickle=True)\n",
    "            if attack_type == 'stat':\n",
    "                stat_acc_list.append(attack_acc)\n",
    "            elif attack_type == 'black':\n",
    "                black_acc_list.append(attack_acc.item()['test'])\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print('File not found: ', class_repeat_path)\n",
    "        continue\n",
    "\n",
    "print('{:.4f} {:.4f} {:.4f} {:.4f} {:.4f}'.format(\n",
    "    np.average(train_acc_list), np.average(valid_acc_list), np.average(test_acc_list),\n",
    "    np.average(stat_acc_list), np.average(black_acc_list),\n",
    "))\n",
    "# print(np.average(train_acc_list), np.average(valid_acc_list), np.average(test_acc_list))\n",
    "# print(np.average(stat_acc_list), np.average(black_acc_list), np.average(test_acc_list))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% original_setsize2000\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}